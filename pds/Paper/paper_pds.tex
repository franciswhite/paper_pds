\documentclass{article}
\title{Philosophy of Distributional Semantics\\
\large Best Practices for the Application of Computational Methods to Questions of Meaning}
\date{}
\author{Silvan Hungerb{\"u}hler}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}

%\usepackage{biblatex}
%\addbibresource{pds_references.bib}
\usepackage{csquotes}
\begin{document}
\maketitle
\begin{abstract}
The increase in availability of data and advances in statistical methods has led to the use of Machine Learning (ML) technology in an immense variety of societal domains. ML algorithms are used to inform decisions as diverse and life-changing as access to financial credit, incarceration, university admission, medical treatment or the boundaries of espionage by the NSA.
The use of this technology is not always unproblematic, as its careless application can cause serious harm, even if such effects occur unintentionally.
The seriousness of the potential to systematically disadvantage people has led to a recent debate concerning ethical guidelines and best practices for the general use of ML.
Little has been said, however, about the proper use of algorithms in the specific field of Distributional Semantics (DS). Some researchers have called attention to possible dangers of using ML in DS, as it harbours the potential to reinforce harmful biases along dimensions of race and gender.
The present paper contains an overview over the current state of the \emph{general} discussion 
and draws on these existing insights from different domains of ML to provide guidelines and best practices for computational methods in DS.
As the domain of DS differs in important aspects from other domains of ML, 
we assess these difference with respect on the impact they have on the applicability of general purpose ML guidelines to DS.
\end{abstract}
\section{Introduction}
\paragraph{Motivation}
1-2 paragraphs, talk about application, overall field

As vast amounts of digital data have become available over past decades, algorithms are employed to use the data in order to aid decisions all across society. 
Algorithms have a say in determining who is granted mortgages, who is released on bail or invited for job applications. 
\cite{algorithms2016}
The theory behind these algorithms is \emph{machine learning}.
Although it seems clear that most designers of machine learning algorithms do not harbor malicious intent, the risk of unwillingly harming people is real.
Data processed by machine learning techniques often contains societal prejudice and bias, so that unquestioningly using them for decision making can severely reinforce society's existing biases.
A related issue is that data available to the algorithms may systematically omit information relevant to what it is trying to uncover, as when minority groups are not adequately represented in the data.
Yet another issue is that machine learning techniques may use useful patterns and relationships in the data that are really mirrorring historical factors of discrimination and marginalization. \cite{barocas2016big}

Recently, machine learning techniques used for the computer-based study of language meaning - a field known as \emph{Computational Distributional Semantics} - has come under scrutiny.
Various studies have shown that these methods yield results which are in important ways biased against particular groups as, for example, women. \cite{google}
%\begin{quote}
%In the years since, several disparate impact cases have made their way to the Supreme Court and lower courts, most having to do with employment discrimination. This June, the Supreme Court’s decision in Texas Dept. of Housing and Community Affairs v. Inclusive Communities Project, Inc. affirmed the use of the disparate impact theory to fight housing discrimination. The Inclusive Communities Project had used a statistical analysis of housing patterns to show that a tax credit program effectively segregated Texans by race. Sorelle Friedler, a computer science 
%researcher at Haverford College and a fellow at Data \& Society, called the Court’s decision “huge,” both “in favor of civil rights…and in favor of statistics.”
%\end{quote}

%\paragraph{Contribution}
%largest part of intro, preview of paper, methodology!

The realization that algorithms fed on big data have the potential to amplify structural discrimination and systematically commit grave errors has led to the emergence of a variety of principles, concrete guidelines and public as well as institutional scrutiny.
In the present paper we want to draw on the existing efforts made by experts in the fields of ethics, computer science, public policy and law to extend these principles and guidelines to the field of DS. Specifically, we will use the \emph{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms} issued by FAT/ML (Fairness, Accountability and Transparency in Machine Learning) - a consortium of researches and experts from private and public organizations working on ML. 
The principles comprise five guiding principles: responsibility, explainability, accuracy, auditibility and fairness \cite{principles}.
We will assess potential violation of techniques used in distributional semantics for each of these principles and, where applicable, issue guidelines to prevent their negative impact upon vulnerable groups.
%\paragraph{Paper Overview}

The paper is structured as follows: In \hyperlink{sec2}{Section 2} we first give a very brief introduction to the field of ML in general, before providing some background on the particular algorithmic techniques employed in DS. Especially for the latter we want to provide overview over societal domains where such technology is currently applied and could conceivably be applied in the future. \hyperlink{sec3}{Section 3} contains a discussion of the important ways in which DS, as a particular application of big data analysis, differs from other instances of ML. For the present paper these particularities are important insofar as they entail differences when it comes to its risks and accountabilities across the spectrum of ML. In \hyperlink{sec4}{Section 4}, then, we try to apply the \emph{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms} by FAT/ML to the specific case of DS. \hyperlink{sec5}{Section 5} contains concluding remarks while \hyperlink{sec6}{Section 6} lists the references.
\section{Machine Learning and Distributional Semantics}\hypertarget{sec3}{ }
The term \emph{Machine Learning} is an umbrella term for a variety of statistical methods that, when presented with a series of examples, are able to \emph{learn} from them. That is, the the set of examples - often called the \emph{training data} - is not simply memorized but generalizable knowledge extracted from it. \cite{domingos2012few}
 What is learned are patterns and relationships within the training data and the result is a statistical description - or \emph{model} - of the training data. \cite{fayyad2001digital}  
 The
\section{Guidelines for Machine Learning}\hypertarget{sec2}{}

\section{Application to DS}\hypertarget{sec4}{ }
\paragraph{What's the same: --}
\paragraph{What's different: Double-nature of textual corpora}
\section{Conclusion}

\section{References}\hypertarget{sec5}{ }
%\printbibliography

\end{document}