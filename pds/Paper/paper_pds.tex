\documentclass{article}
\title{Philosophy of Distributional Semantics\\
\large Best Practices for the Application of Computational Methods to Questions of Meaning}
\date{}
\author{Silvan Hungerb{\"u}hler}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}

%\usepackage{biblatex}
%\addbibresource{pds_references.bib}
\usepackage{csquotes}
\begin{document}
\maketitle
\begin{abstract}
The increase in availability of data and advances in statistical methods has led to the use of Machine Learning (ML) technology in an immense variety of societal domains. ML algorithms are used to inform decisions as diverse and life-changing as access to financial credit, incarceration, university admission, medical treatment or the boundaries of espionage by the NSA.
The use of this technology is not always unproblematic, as its careless application can cause serious harm, even if such effects occur unintentionally.
The seriousness of the potential to disrespect people's privacy and integrity or systematically disadvantage specific groups has led to a recent debate concerning ethical guidelines and best practices for the general use of ML.
Little has been said, however, about the proper use of algorithms in the specific field of Distributional Semantics (DS). Some researchers have called attention to possible dangers of using ML in DS, as it harbours the potential to reinforce harmful biases along dimensions of race and gender.
The present paper wants to point to one particular attempt to provide general-purpose guidelines for ML and draw on these existing insights to suggest guidelines and best practices for computational methods in DS.
As the domain of DS differs in important aspects from other domains of ML, notably Natural Language Processing (NLP),
we assess these difference with respect on the impact they have on the applicability of general purpose ML guidelines to DS.
\end{abstract}
\section{Introduction}
%1-2 paragraphs, talk about application, overall field
\paragraph{Place of Machine Learning in society}
As vast amounts of digital data have become available over past decades, algorithms are employed to use the data in order to take and inform decisions all across society. 
Algorithms have a say in determining who is granted mortgages, who is released on bail or invited for job applications. 
\cite{algorithms2016}
The theory behind these algorithms is \emph{machine learning}.
Although most inventors and designers of machine learning algorithms do not harbor malicious intent, the risk of unwillingly harming people is real.
\paragraph{Harmful Effects}
There are several different sources of harmful effects that these techniques can bring about.

A first concern is the issue of privacy. Since very large amounts of data are required for these methods to be effective, great efforts are devoted to collecting large data sets. Depending on the issue at hand, these data sets may contain highly sensitive information about individuals or organizations. It is thus of importance who gets to see these data and in what they are protected from third parties accessing them. There have been reported cases of researchers working with large corpora of texts containing peoples' complete medical record who sent these files indiscriminately around by email. A second aspect of privacy is how the data is collected in the first place. It is a question of ethical concern whether the individuals whose data is collected agree to their personal information being used. What the standards should be here isstill  far from clear as automated data-mining techniques gain popularity.

A second point concerns the disruptive potential machine learning techniques have on labor markets. As ever more cognitive tasks can be automated, the economic landscape of service sector economies is bound undergo change. Some workers will without a doubt be disadvantaged by these changes. It must concern the inventors and implentors of such technology what happens here.

A third difficult point is the so-called \emph{double use} problem. New technology's use is often underspecified and could be used for benefit of humanity or to its detriment. Chat-bots developed by researchers in automated natural language processing, to name a concrete example, can be used to assist people to access governmental health-care serices, yet they have reportedly been used by the Mexican government to disrupt political discussions deemed subversive on social media. \cite{leidner2017ethical}

Finally, machine learning harbours the potential to amplify structural discrimination and systematically disadvantage people because of their race, gender or other social category. If the models which are trained algorithmically are fed biased data, then predictions or classifications they make will reflect that bias.
Data processed by machine learning techniques often contains societal prejudice and bias, so that unquestioningly using them for decision making can severely reinforce society's existing biases. A related issue is that data available to the algorithms may systematically omit information relevant to what it is trying to uncover, as when minority groups are not adequately represented in the data. Yet another issue is that machine learning techniques may use useful patterns and relationships in the data that are really mirrorring historical factors of discrimination and marginalization. \cite{barocas2016big}

In the present essay, we will mostly be concerned with the last of these problematic issues surrounding machine learning.

%\begin{quote}
%In the years since, several disparate impact cases have made their way to the Supreme Court and lower courts, most having to do with employment discrimination. This June, the Supreme Court’s decision in Texas Dept. of Housing and Community Affairs v. Inclusive Communities Project, Inc. affirmed the use of the disparate impact theory to fight housing discrimination. The Inclusive Communities Project had used a statistical analysis of housing patterns to show that a tax credit program effectively segregated Texans by race. Sorelle Friedler, a computer science 
%researcher at Haverford College and a fellow at Data \& Society, called the Court’s decision “huge,” both “in favor of civil rights…and in favor of statistics.”
%\end{quote}

%\paragraph{Contribution}
%largest part of intro, preview of paper, methodology!
\paragraph{Public Attention is in ML minor extent in NLP, not in DS}
Many of the issues lately mentioned are of great importance to modern society at large. Consequently, with the rise of big data people working at the intersection of information technology and ethics have attempted to lay down foundations on how to handle these technologies. Many of these efforts have naturally been directed at the broad topic of machine learning in general.\cite{leidner2017ehtical} Only very recently the discussion has turned on machine learning used for analysis and modeling of language - often referred to as \emph{natural language processing}. Presumably because this is only one of many particular fields where machine learning is applied and the discussion of ethics natural language processing is bound pertain to less cases of applications throughout society, it took some time for the discussion to reach this field.

Recently, however, a discussion has opened up in a hitherto completely unmentioned domain. Machine learning techniques used for the computer-based study of language meaning - a field known as \emph{computational distributional semantics} - has come under scrutiny.
Various studies have shown that these methods yield results which are in important ways biased against particular groups as, for example, women \cite{google} \cite{wagner2015s}.The realization that algorithms fed on big data come with a host of problematic issues has led to the emergence of a variety of principles, concrete guidelines and public as well as institutional scrutiny.

\paragraph{Contribution: Drawing on ML discussion for DS}
In the present paper we want to draw on the existing efforts made by experts in the fields of ethics, computer science, public policy and law to extend these principles and guidelines to the field of DS. Specifically, we will use the \emph{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms} (PAASISA) issued by an organization called \emph{Fairness, Accountability and Transparency in Machine Learning} - a consortium of researches and experts from private and public organizations working on machine learning. 
The PAASISA comprise five guiding principles: responsibility, explainability, accuracy, auditibility and fairness \cite{principles}.
We will assess potential violation of techniques used in distributional semantics for each of these principles and, where applicable, issue guidelines to prevent their negative impact upon vulnerable groups. 

We want to focus on aspects of discrimination and bias in the outcome because these issues are least explored. Debates concerning privacy etc. would seem to follow the same lines as the discussion to establish general purpose ethical principles for machine learning, while the issue of discrimination and bias has a special relation to DS.

\paragraph{Methodoology}
The method employed by the present contribution is one of scanning previous efforts in a similar vein, identifying useful parts and applying them to ethical questions surrounding distributional semantics. There will be no foundational efforts undertaken to sustain the validity of the principles thus transferred.  Their validity is presupposed. The analysis contained in this contribution merely serves to disucss the usefulness of the principles in particular domain, and assert it where due.

\paragraph{Paper Overview}
The paper is structured as follows: In \hyperlink{sec2}{Section 2} we first give a very brief introduction to the field of machine learning in general, before providing some background on the algorithmic techniques employed in distributional semantics. Especially for the latter we want to provide overview over societal domains where such technology is currently applied and could conceivably be applied in the future. \hyperlink{sec3}{Section 3} contains a discussion of the important ways in which DS, as a particular application of big data analysis, differs from other instances of ML. For the present paper these particularities are important insofar as they entail differences when it comes to its risks and accountabilities across the spectrum of ML. In \hyperlink{sec4}{Section 4}, then, we try to apply the \emph{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms} by FAT/ML to the specific case of DS. \hyperlink{sec5}{Section 5} contains concluding remarks while \hyperlink{sec6}{Section 6} lists the references.
\section{Machine Learning, Natural Language Processing and Distributional Semantics}\hypertarget{sec3}{ }
\paragraph{What is ML?}
The term \emph{Machine Learning} is an umbrella term for a variety of statistical methods that are able to \emph{learn} from a series of examples presented to them. The the set of examples - often called the \emph{training data} - is not simply memorized but the machine learning algorithm extracts generalizable knowledge \cite{domingos2012few}.
 What the algorithm learns are patterns and relationships within the training data and the result of the learning process is a statistical description - or \emph{model} - of the training data \cite{fayyad2001digital}.
\paragraph{What is NLP?}
\paragraph{Relation: ML - NLP}
\paragraph{What is Distributional Semantics?}
Distributional semantics is a linguistic theory of meaning looking to represent lexical meaning of expressions as a function of the context in which they appear. It theoretically foundation is the so-called \emph{distributional hypothesis} which holds that two expressions are similar in meaning, if they occur in similar contexts \cite{harris1954distributional}.
Althought it was originally developed as a distributional theory - in the sense that ... - in the middle of the 20th century, it can be seen as following the footsteps of structural linguists, notably Bloomfield \cite{bloomfield}
More info on DS. use \cite{boleda2016formal}

The theoretical framework of distributional semantics has become widely used and further developed as the advent and success of computational methods have enabled linguist to build large-scale models of linguistic meaning using digitalised corpora of text. 

\paragraph{Relation: NLP - DS}
DS is naturally concerned with a narrower topic: meaning.\\
Meaning is a notoriously difficult topic conceptually.\\
DS sits at the intersection of ethically touchy topics: capturing/reporting/describing bias leads to reenforcing bias. results can be highly sensitive to data selection. even if results are valid there are issues of over/under-representation (scottish accent),
 
\paragraph{The state of the ethical discussion in ML, NLP and DS}
-ML well underway. series of legal, political and cs studies on the topic. many articles in non-technical or academic media. be specific, mention FATML. use nlp ethic article to get overview.\\
-NLP has seen some movement in the last couple of years. some conferences on ethical issues. even concrete proposals for best practices.\\
-DS in particular has seen little attention.

\paragraph{What good should come from looking at DS?}
-focus not on dual-use or bad treatment of mechanical turks, but the question how bias in meaning is dangerous.\\
-Why not ethics by design
\section{Guidelines for Machine Learning}\hypertarget{sec2}{}
\paragraph{Introduce FATML}
Algorithmically informed decisions are used in ever more domains of the private and public sectors and thus have the potential to impact society in significant ways. In many cases of undesirable effects that come with these technologies, legislation is behind in adequately protecting people negatively affected by it.

Given this state of affairs, it is important to hold the people who develop or implement such algorithmic systems accountable to the public. The FAT-ML concisely write in their PAA \cite{principles}
\begin{quote}
Algorithms and the data that drive them are designed and created by people -- There is always a human ultimately responsible for decisions made or informed by an algorithm. ''The algorithm did it'' is not an acceptable excuse if algorithmic systems make mistakes or have undesired consequences, including from machine-learning processes.
\end{quote}

The document then goes on to name five principles that should guide developders of algorithms in designing and implementing their systems. The authors of PAA urge creators to issue a Social Impact Statement wherein they detail the effect of their product has on society with respect to the five principles. In this way the principles are associated with best practices in the ...

\paragraph{5 Principles, quick recap of each of them}

We will now briefly go over the five principles to explaint their content.



\section{Application to DS}\hypertarget{sec4}{ }
\paragraph{What's the same: --}
\paragraph{What's different: Double-nature of textual corpora}
\section{Conclusion}

\section{References}\hypertarget{sec5}{ }
%\printbibliography

\end{document}