\documentclass{article}
\title{Philosophy of Distributional Semantics\\
\large Best Practices for the Application of Computational Methods to Questions of Meaning}
\date{}
\author{Silvan Hungerb{\"u}hler}
\usepackage{enumitem}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{comment}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}

%\usepackage{biblatex}
%\addbibresource{pds_references.bib}
\usepackage{csquotes}
\begin{document}
\maketitle
\begin{abstract}
The increase in availability of data and advances in statistical methods has led to the use of Machine Learning (ML) technology in an immense variety of societal domains. ML algorithms are used to inform decisions as diverse and life-changing as access to financial credit, incarceration, university admission, medical treatment or the legal boundaries of espionage by the NSA.
The use of this technology is not always unproblematic, as its careless application can cause serious harm, even if such effects occur unintentionally.
The seriousness of the potential to disrespect people's privacy and integrity or systematically disadvantage specific groups has led to a recent debate concerning ethical guidelines and best practices for the general use of ML.
Little has been said, however, about the proper use of algorithms in the specific field of Distributional Semantics (DS). Some researchers have called attention to possible dangers of using ML in DS, as it harbours the potential to reinforce harmful biases along dimensions of race and gender.
The present paper wants to point to one particular attempt to provide general-purpose guidelines for ML and draw on these existing insights to suggest guidelines and best practices for computational methods in DS.
As the domain of DS differs in important aspects from other applications of ML, notably also for Natural Language Processing (NLP),
this involves assessing  the applicability of general purpose ML guidelines to DS with these difference in mind.
\end{abstract}
\section{Introduction}
%1-2 paragraphs, talk about application, overall field
\paragraph{Place of Machine Learning in society}
As vast amounts of digital data have become available over past decades, algorithms are employed to use the data in order to take and inform decisions all across society. 
Algorithms have a say in determining who is granted mortgages, who is released on bail or invited for job applications. 
\cite{algorithms2016}
The theory behind many of these algorithms is \emph{machine learning} (ML).
Although most inventors and designers of ML algorithms certainly do not harbor malicious intent, the risk of unwillingly harming people is real.

\paragraph{Harmful Effects}
There are several different sources of harmful effects that these techniques can bring about. With the very large data collected, stored and processed, issues of privacy arise naturally. Especially when data mining techniques are used to scrape the web, people's explicit consent to provide their data can easily go by the board. Another recurrent problem is the two-sided nature of any technology: it can be used for the good or for dubious purposes, as fraud or spying, for example. Finally, big data and ML approaches brings the risk of reenforcing structural bias along racial, gender or others social lines in society. Models trained on biased historical data, for example, have been used to determine prison sentences which lead to consistently biased outcomes against blacks and latinos in the United States of America, land of the brave and home of the free \cite{angwin2016machine}.



In the present essay, we will mostly be concerned with the last of these problematic issues surrounding machine learning.

%\begin{quote}
%In the years since, several disparate impact cases have made their way to the Supreme Court and lower courts, most having to do with employment discrimination. This June, the Supreme Court’s decision in Texas Dept. of Housing and Community Affairs v. Inclusive Communities Project, Inc. affirmed the use of the disparate impact theory to fight housing discrimination. The Inclusive Communities Project had used a statistical analysis of housing patterns to show that a tax credit program effectively segregated Texans by race. Sorelle Friedler, a computer science 
%researcher at Haverford College and a fellow at Data \& Society, called the Court’s decision “huge,” both “in favor of civil rights…and in favor of statistics.”
%\end{quote}

%\paragraph{Contribution}
%largest part of intro, preview of paper, methodology!
\paragraph{Public Attention is in ML minor extent in NLP, not in DS}
Many of the issues lately mentioned are of great importance to modern society at large, especially as. Consequently, people working at the intersection of information technology and ethics have attempted to lay down foundations on how to handle these technologies. Many of these efforts have naturally been directed at the broad topic of machine learning in general.\cite{leidner2017ehtical} Only a few years ago the discussion has turned on the specific use of ML for analysis and modeling of language - often referred to as \emph{natural language processing}. Presumably because this is only one of many particular fields where machine learning is applied and the discussion of ethics natural language processing is bound to pertain to less cases of applications throughout society, it took some time for the discussion to reach this field.

A recently as 2016, however, a discussion has opened up in a hitherto completely unmentioned domain. Machine learning techniques used for the computer-based study of language meaning - a field known as \emph{computational distributional semantics} - has come under scrutiny.
Various studies have shown that these methods yield results which are in important ways biased against particular groups as, for example, women \cite{google} \cite{wagner2015s}.
\textbf{Why this is important. Mention Google searches using semantic information.} 

The realization that algorithms fed on big data come with a host of problematic issues has led to the emergence of a variety of principles, concrete guidelines and public as well as institutional scrutiny.

\paragraph{Contribution: Drawing on ML discussion for DS}
In the present paper we want to draw on the existing efforts made by experts in the fields of ethics, computer science, public policy and law to extend these principles and guidelines to the field of distributional semantics. Specifically, we will use the \emph{Principles for Accountable Algorithms} (PAA) issued by the organization \emph{Fairness, Accountability and Transparency in Machine Learning} (FATML) - a consortium of researches and experts from private and public organizations working on machine learning. 
The PAA comprise five guiding principles: responsibility, explainability, accuracy, auditibility and fairness \cite{principles}.
We will assess potential violation of techniques used in distributional semantics for each of these principles and, where applicable, issue guidelines to prevent their negative impact upon vulnerable groups. 

Currently, we want to focus on aspects of discrimination and bias in the outcome of distributional semantics models for two reasons. For one, these are the least explored ethical issues for distributional semantics. Many of the ideas, guidelines and principles concerning privacy, double use or economic impact are directly transferable from the general machine learning debate to any sub-field that similarly employs big data and algorithms. Computational distributional semantics is no exception. Debates concerning privacy etc. can follow the same lines as the discussion to establish general purpose ethical principles for machine learning. The issue of discrimination and bias, however, has a special relation to distributional semantics because the field occupies a unique position of computational language research. The central concern of distributional semantics, as its name gives away, is the concept of meaning. As we will argue presently, this relates it in a special way to many sensitive topics in the general machine learning discussion. Put succinctly, it sits at the intersection of concerns pertaining to data selection, validity or questionability of computational methods, interpretation of results and usage thereof.

\paragraph{Methodoology}
The method employed by the present contribution is one of scanning previous efforts in a similar vein, identifying useful parts and applying them to ethical questions surrounding distributional semantics. There will be no foundational efforts undertaken to sustain the validity of the principles thus transferred.  Their validity is presupposed. The analysis contained in this contribution merely serves to discuss the usefulness of the principles in particular domain, and assert it where due.

\paragraph{Paper Overview}
The paper is structured as follows: In \hyperlink{sec2}{Section 2} we first give a very brief description of machine learning, natural language processing and distributional semantics as well as their relation to each other. Especially for distributional semantics we want to provide overview over societal domains where such technology is currently applied and could conceivably be applied in the future. \hyperlink{sec3}{Section 3} contains a discussion of the important ways in which DS, as a particular application of big data analysis, differs from other instances of ML. For the present paper these particularities are important insofar as they entail differences when it comes to its risks and accountabilities across the spectrum of ML. In \hyperlink{sec4}{Section 4}, then, we try to apply the \emph{Principles for Accountable Algorithms and a Social Impact Statement for Algorithms} by FAT/ML to the specific case of DS. \hyperlink{sec5}{Section 5} contains concluding remarks while \hyperlink{sec6}{Section 6} lists the references.
\section{Machine Learning, Natural Language Processing and Distributional Semantics}\hypertarget{sec3}{ }
\paragraph{What is ML?}
The term \emph{Machine Learning} is an umbrella term for a variety of statistical methods that are able to \emph{learn} from a series of examples presented to them. The the set of examples - often called the \emph{training data} - is not simply memorized but the machine learning algorithm extracts generalizable knowledge \cite{domingos2012few}.
 What the algorithm learns are patterns and relationships within the training data and the result of the learning process is a statistical description - or \emph{model} - of the training data \cite{fayyad2001digital}.
\paragraph{What is NLP?}
Natural language processing is a field of research that uses computational tools to build natural language text or speech applications. It is related to computational linguistic, an area of linguistic that uses computational techniques to get a scientific understanding of natural language. The knowledge thus obtained can be used in natural language processing to develop computer systems that serve a wide variety of purposes. Principal applications include translation between natural languages, artificial intelligence, user interfaces, like chat-bots, for example, summarization of text or speech recognition \cite{chowdhury2003natural}.
\paragraph{Relation: ML - NLP}
The area of natural language processing frequently serves itself of methods from machine learning, for example to process very large textual corpora. Indeed, parts of natural language processing can be thought of as particular applications of machine learning techniques to the domain of natural language.
\paragraph{What is Distributional Semantics?}
Distributional semantics is a linguistic theory of meaning looking to represent lexical meaning of expressions as a function of the context in which they appear. Its theoretically foundation is the so-called \emph{distributional hypothesis} which holds that two expressions are similar in meaning, if they occur in similar contexts \cite{harris1954distributional}.
%Althought it was originally developed as a distributional theory - in the sense that ... - in the middle of the 20th century, it can be seen as following the footsteps of structural linguists, notably Bloomfield \cite{bloomfield}

The theory of distributional semantics has been used successfully in computational semantics - an branch of computational lingiustics -, as it has become possible to obtain semantic representations immediately from natural language data. The theoretical framework of distributional semantics has become widely used and further developed as the advent and success of computational methods have enabled linguist to build large-scale models of linguistic meaning using digitalised corpora of text. 
Following the distributional hypothesis, the meaning of an expression is a function of the context in which it occurs, where context can be construed in different ways. Most typically, it is other words surrounding an expression in a text - the sentence in which it appears, for example. Context is not restricted to such simple analysis, however, as it can possibly contain more complex syntactic relations within a text, or even visual, textual or auditory information gathered from data.
\cite{boleda2016formal}
Distributional semantics, then, takes the context in which an expression occurs and abstracts away from the particular contexts in a large corpus of natural language data. The mathematical vehicle for representing these abstractions are commonly vectors, but there are also other algebraic objects possible, as matrices or tensors. The meaning of an expression, as a function of its context, is then represented by the distribution across the dimensions of the vector. A set of words thus represented builds a semantic space - mathematically, a vector space - wherein one can study the semantic relationship between the expressions because some semantic relationships between expressions are mirrored by geometric relationship in these spaces.

\paragraph{Relation: NLP - DS}
Distributional semantics is concerned with the specific topic of meaning in the study of natural language. If viewed from an application-oriented standpoint it could be seen as one of many sub-fields of natural language processing research. Indeed, as far as the present paper is concerned, it is precisely the application of distributional semantics in industry that warrants heightened attention.
From a philosophical standpoint, it is notoriously difficult to come to grips with the concept of meaning .
Distributional semantics sits at the intersection of ethically touchy topics. 
First off, consider the situation where a meaning space is constructed based on some seemingly innocuous corpus and ends up containing severe bias along lines of gender or racial stereotypes. A recent study has found, for example, that a model trained on Google News articles display significant bias along binary gender dimensions \cite{bolukbasi2016man}. This raises a host of questions concerning the provenance of the bias, the adequate response by the responsible distributional semanticist and, not to mention, the nature of meaning.

Does one have to live with the fact that the meanings discovered in some corpus systematically contain unfavourable connotations for some group of people? After all, the corpus was produced by a particular society, so it should be expected that it mirror that society's prejudices. Is the stance "the model picked up what it is supposed to pick up, blame society" a fair one, or has the computational linguist the moral obligation to rid her model of biased meaning representations?

Fair and square, the model contains bias because the corpus contains bias. What if the semantic model is further used for some interaction within that same society that taught it - via corpus - what it means to be a \emph{woman}, will the bias be further re-enforced? It is has been reported that when one queries Google with the name of a person, then Google is more likely to show advertisement related to that person being arrested if the name's connotation is black \cite{sweeney2013discrimination}.
%A related issue is that even if results are valid, the of over-, or, respectively, under-representation of specific items in the data can disadvantage group. 

\paragraph{The state of the ethical discussion in ML, NLP and DS}
For the domain general use of machine learning techniques there exists a series of studies by now from legal, political computer science experts which specify principles and guidelines. Furthermore, many non-technical articles have been published outside of academic channels. 
be specific, mention FATML. \\
\textbf{use nlp ethic article to get overview. do this shits.}

In the case of natural language processing there has been  has seen some movement in the last couple of years.
For machine learning and natural language processing there are several  conferences on ethical issues by now.
http://www.ethicsinnlp.org/related-conferences


 even concrete proposals for best practices.\\
-DS in particular has seen little attention.

\paragraph{What good should come from looking at DS?}
-focus not on dual-use or bad treatment of mechanical turks, but the question how bias in meaning is dangerous.\\
-Why not ethics by design
A first concern is the issue of privacy. Since very large amounts of data are required for these methods to be effective, great efforts are devoted to collecting large data sets which may contain highly sensitive information about individuals or organizations. It is thus of importance who gets to see these data and how they are protected from third parties accessing them. There have been reported cases of researchers working with large corpora of texts containing peoples' complete medical record who sent these files indiscriminately around by email. A second aspect of privacy is how the data is collected in the first place. It is a question of ethical concern whether the individuals whose data is collected agree to their personal information being used. What the standards should be here isstill  far from clear as automated data-mining techniques gain popularity.

A second point concerns the disruptive potential machine learning techniques have on labor markets. As ever more cognitive tasks can be automated, the economic landscape of service sector economies is bound undergo change. Some workers will without a doubt be disadvantaged by these changes. It must concern the inventors and implentors of such technology what happens here.

A third difficult point is the so-called \emph{double use} problem. New technology's use is often underspecified and could be used for benefit of humanity or to its detriment. Chat-bots developed by researchers in automated natural language processing, to name a concrete example, can be used to assist people to access governmental health-care serices, yet they have reportedly been used by the Mexican government to disrupt political discussions deemed subversive on social media. \cite{leidner2017ethical}

Finally, machine learning harbours the potential to amplify structural discrimination and systematically disadvantage people because of their race, gender or other social category. If the models which are trained algorithmically are fed biased data, then predictions or classifications they make will reflect that bias.
Data processed by machine learning techniques often contains societal prejudice and bias, so that unquestioningly using them for decision making can severely reinforce society's existing biases. A related issue is that data available to the algorithms may systematically omit information relevant to what it is trying to uncover, as when minority groups are not adequately represented in the data. Yet another issue is that machine learning techniques may use useful patterns and relationships in the data that are really mirrorring historical factors of discrimination and marginalization. \cite{barocas2016big}

\section{Guidelines for Machine Learning}\hypertarget{sec2}{}
\paragraph{Introduce FATML}
Algorithmically informed decisions are used in ever more domains of the private and public sectors and thus have the potential to impact society in significant ways. In many cases of undesirable effects that come with these technologies, legislation is behind in adequately protecting people negatively affected by it.

Given this state of affairs, it is important to hold the people who develop or implement such algorithmic systems accountable to the public. The FAT-ML concisely write in their PAA \cite{principles}
\begin{quote}
Algorithms and the data that drive them are designed and created by people -- There is always a human ultimately responsible for decisions made or informed by an algorithm. ''The algorithm did it'' is not an acceptable excuse if algorithmic systems make mistakes or have undesired consequences, including from machine-learning processes.
\end{quote}

The document then goes on to name five principles that should guide developders of algorithms in designing and implementing their systems. The authors of PAA urge creators to issue a Social Impact Statement wherein they detail the effect of their product has on society with respect to the five principles. In this way the principles are associated with a set of best practices.
\paragraph{5 Principles, quick recap of each of them}
We will now briefly go over the five principles - \emph{responsibility, explanability, accuracy, auditability and fairness} to explain their intention.
Responsibility requires developers to take into account possible adverse effects of their algorithmic system. There should be designated roles within the organization.


\section{Application to DS}\hypertarget{sec4}{ }
\paragraph{What's the same: --}
\paragraph{What's different: Double-nature of textual corpora}
\section{Conclusion}

\section{References}\hypertarget{sec5}{ }
%\printbibliography

\end{document}